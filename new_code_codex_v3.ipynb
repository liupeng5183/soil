{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9705cc-2c3b-4ce2-8d42-489f24bb75e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input shapefile is invalid.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'geemap' has no attribute 'ee_to_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 294\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExport task started.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# pragma: no cover - script entry\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 264\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    261\u001b[0m boundary \u001b[38;5;241m=\u001b[39m load_boundary(BOUNDARY_PATH)\n\u001b[1;32m    262\u001b[0m feature_image \u001b[38;5;241m=\u001b[39m build_feature_stack(boundary)\n\u001b[0;32m--> 264\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43msample_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOIL_DATA_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_samples.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    267\u001b[0m results, X_test, y_test \u001b[38;5;241m=\u001b[39m train_models(df)\n",
      "Cell \u001b[0;32mIn[2], line 164\u001b[0m, in \u001b[0;36msample_points\u001b[0;34m(image, boundary, sample_path)\u001b[0m\n\u001b[1;32m    157\u001b[0m samples \u001b[38;5;241m=\u001b[39m geemap\u001b[38;5;241m.\u001b[39mshp_to_ee(sample_path)\n\u001b[1;32m    158\u001b[0m sample \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39msampleRegions(\n\u001b[1;32m    159\u001b[0m     collection\u001b[38;5;241m=\u001b[39msamples,\n\u001b[1;32m    160\u001b[0m     properties\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msalinity\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    161\u001b[0m     scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m    162\u001b[0m     geometries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    163\u001b[0m )\n\u001b[0;32m--> 164\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mgeemap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mee_to_pandas\u001b[49m(sample)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'geemap' has no attribute 'ee_to_pandas'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Enhanced salinity prediction pipeline with model comparison and SHAP analysis.\n",
    "This script is adapted from ``new_code_codex_v2.ipynb`` and implements\n",
    "additional features requested in ``README.md``.\n",
    "\n",
    "The pipeline:\n",
    "1. Load remote sensing imagery and sample soil data.\n",
    "2. Train multiple regression models.\n",
    "3. Evaluate models using R2, RMSE and MAE.\n",
    "4. Save predictions from each model to CSV.\n",
    "5. Generate comparison plots and SHAP summaries when possible.\n",
    "6. Export the best model's prediction image via ``geemap.ee_export_image_to_drive``.\n",
    "\n",
    "The script is designed to be run as a standalone Python module after\n",
    "Google Earth Engine authentication.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import ee\n",
    "import geemap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "\n",
    "try:\n",
    "    import shap  # optional, used for explanation\n",
    "    SHAP_AVAILABLE = True\n",
    "except Exception:  # pragma: no cover - shap is optional\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "START_DATE = \"2022-07-01\"\n",
    "END_DATE = \"2022-10-01\"\n",
    "BOUNDARY_PATH = \"/path/to/bdy.shp\"\n",
    "SOIL_DATA_PATH = \"/path/to/soil_samples.csv\"\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "\n",
    "LANDSAT_COLLECTION = \"LANDSAT/LC08/C02/T1_L2\"\n",
    "SENTINEL1_COLLECTION = \"COPERNICUS/S1_GRD\"\n",
    "MODIS_ET_COLLECTION = \"MODIS/061/MOD16A2\"\n",
    "CHIRPS_COLLECTION = \"UCSB-CHG/CHIRPS/DAILY\"\n",
    "SRTM = \"USGS/SRTMGL1_003\"\n",
    "WORLDCOVER = \"ESA/WorldCover/v200\"\n",
    "\n",
    "CLOUD_THRESHOLD = 70\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Utility functions\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def initialize_gee() -> None:\n",
    "    \"\"\"Authenticate and initialize Google Earth Engine.\"\"\"\n",
    "    try:\n",
    "        ee.Initialize()\n",
    "    except Exception:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "\n",
    "\n",
    "def load_boundary(path: str) -> ee.FeatureCollection:\n",
    "    return geemap.shp_to_ee(path)\n",
    "\n",
    "\n",
    "def mask_clouds_l8(image: ee.Image) -> ee.Image:\n",
    "    qa = image.select(\"QA_PIXEL\")\n",
    "    cloud = qa.bitwiseAnd(1 << 3).eq(0)\n",
    "    shadow = qa.bitwiseAnd(1 << 4).eq(0)\n",
    "    snow = qa.bitwiseAnd(1 << 5).eq(0)\n",
    "    mask = cloud.And(shadow).And(snow)\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "\n",
    "def apply_scale(image: ee.Image) -> ee.Image:\n",
    "    optical = image.select(\"SR_B.*\").multiply(0.0000275).add(-0.2)\n",
    "    thermal = image.select(\"ST_B.*\").multiply(0.00341802).add(149.0)\n",
    "    return image.addBands(optical, None, True).addBands(thermal, None, True)\n",
    "\n",
    "\n",
    "def process_landsat(boundary: ee.FeatureCollection) -> ee.Image:\n",
    "    collection = (\n",
    "        ee.ImageCollection(LANDSAT_COLLECTION)\n",
    "        .filterDate(START_DATE, END_DATE)\n",
    "        .filterBounds(boundary)\n",
    "        .map(apply_scale)\n",
    "        .map(mask_clouds_l8)\n",
    "    )\n",
    "    composite = collection.median().clip(boundary)\n",
    "    ndvi = composite.normalizedDifference([\"SR_B5\", \"SR_B4\"]).rename(\"NDVI\")\n",
    "    si = composite.select(\"SR_B2\").multiply(composite.select(\"SR_B4\")).sqrt().rename(\"SI1\")\n",
    "    return composite.addBands([ndvi, si])\n",
    "\n",
    "\n",
    "def process_sentinel1(boundary: ee.FeatureCollection) -> ee.Image:\n",
    "    def mask_edge(image: ee.Image) -> ee.Image:\n",
    "        edge = image.lt(-30.0)\n",
    "        mask = image.mask().And(edge.Not())\n",
    "        return image.updateMask(mask)\n",
    "\n",
    "    collection = (\n",
    "        ee.ImageCollection(SENTINEL1_COLLECTION)\n",
    "        .filterDate(START_DATE, END_DATE)\n",
    "        .filterBounds(boundary)\n",
    "        .filter(ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VV\"))\n",
    "        .filter(ee.Filter.listContains(\"transmitterReceiverPolarisation\", \"VH\"))\n",
    "        .filter(ee.Filter.eq(\"instrumentMode\", \"IW\"))\n",
    "        .map(mask_edge)\n",
    "    )\n",
    "    vv = collection.select(\"VV\").median()\n",
    "    vh = collection.select(\"VH\").median()\n",
    "    ratio = vv.subtract(vh).rename(\"VV_VH_diff\")\n",
    "    return ee.Image.cat([vv, vh, ratio]).clip(boundary)\n",
    "\n",
    "\n",
    "def process_environment(boundary: ee.FeatureCollection) -> ee.Image:\n",
    "    et = (\n",
    "        ee.ImageCollection(MODIS_ET_COLLECTION)\n",
    "        .filterDate(START_DATE, END_DATE)\n",
    "        .filterBounds(boundary)\n",
    "        .select(\"ET\")\n",
    "        .mean()\n",
    "        .rename(\"ET\")\n",
    "    )\n",
    "    precip = (\n",
    "        ee.ImageCollection(CHIRPS_COLLECTION)\n",
    "        .filterDate(START_DATE, END_DATE)\n",
    "        .filterBounds(boundary)\n",
    "        .select(\"precipitation\")\n",
    "        .sum()\n",
    "        .rename(\"Precip\")\n",
    "    )\n",
    "    dem = ee.Image(SRTM)\n",
    "    slope = ee.Terrain.slope(dem).rename(\"slope\")\n",
    "    return ee.Image.cat([et, precip, dem.rename(\"elevation\"), slope]).clip(boundary)\n",
    "\n",
    "\n",
    "def build_feature_stack(boundary: ee.FeatureCollection) -> ee.Image:\n",
    "    l8 = process_landsat(boundary)\n",
    "    s1 = process_sentinel1(boundary)\n",
    "    env = process_environment(boundary)\n",
    "    worldcover = ee.ImageCollection(WORLDCOVER).first().select(\"Map\")\n",
    "    return ee.Image.cat([l8, s1, env, worldcover.rename(\"landcover\")])\n",
    "\n",
    "\n",
    "def sample_points(image: ee.Image, boundary: ee.FeatureCollection, sample_path: str) -> pd.DataFrame:\n",
    "    samples = geemap.shp_to_ee(sample_path)\n",
    "    sample = image.sampleRegions(\n",
    "        collection=samples,\n",
    "        properties=[\"salinity\"],\n",
    "        scale=30,\n",
    "        geometries=True,\n",
    "    )\n",
    "    df = geemap.ee_to_pandas(sample)\n",
    "    return df.dropna()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Model training and evaluation\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def train_models(df: pd.DataFrame) -> Tuple[Dict[str, Dict], pd.DataFrame, pd.Series]:\n",
    "    X = df.drop(columns=[\"salinity\", \"longitude\", \"latitude\"], errors=\"ignore\")\n",
    "    y = df[\"salinity\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "        \"SVR\": SVR(),\n",
    "        \"Linear\": LinearRegression(),\n",
    "        \"XGB\": xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42),\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"RandomForest\": {\"n_estimators\": [100, 200], \"max_depth\": [5, 10]},\n",
    "        \"SVR\": {\"C\": [1, 10], \"gamma\": [\"scale\", \"auto\"]},\n",
    "        \"Linear\": {},\n",
    "        \"XGB\": {\"n_estimators\": [100, 200], \"max_depth\": [3, 6]},\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    metrics_list = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        grid = GridSearchCV(\n",
    "            model, params[name], cv=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        pred = grid.predict(X_test)\n",
    "\n",
    "        r2 = r2_score(y_test, pred)\n",
    "        rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "        mae = mean_absolute_error(y_test, pred)\n",
    "\n",
    "        metrics_list.append({\"model\": name, \"R2\": r2, \"RMSE\": rmse, \"MAE\": mae})\n",
    "        results[name] = {\"model\": grid.best_estimator_, \"pred\": pred}\n",
    "\n",
    "        # save predictions\n",
    "        pred_df = pd.DataFrame({\"actual\": y_test.values, \"pred\": pred})\n",
    "        pred_df.to_csv(os.path.join(OUTPUT_DIR, f\"{name}_predictions.csv\"), index=False)\n",
    "\n",
    "        # feature importance\n",
    "        if hasattr(grid.best_estimator_, \"feature_importances_\"):\n",
    "            importances = grid.best_estimator_.feature_importances_\n",
    "            imp_df = pd.DataFrame({\"feature\": X_train.columns, \"importance\": importances})\n",
    "            imp_df.sort_values(\"importance\", ascending=False).to_csv(\n",
    "                os.path.join(OUTPUT_DIR, f\"{name}_feature_importance.csv\"), index=False\n",
    "            )\n",
    "\n",
    "        # SHAP explanation\n",
    "        if SHAP_AVAILABLE:\n",
    "            explainer = shap.Explainer(grid.best_estimator_, X_train)\n",
    "            shap_values = explainer(X_test)\n",
    "            shap_df = pd.DataFrame(shap_values.values, columns=X_train.columns)\n",
    "            shap_df.to_csv(os.path.join(OUTPUT_DIR, f\"{name}_shap_values.csv\"), index=False)\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values, X_test, show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUTPUT_DIR, f\"{name}_shap_summary.png\"))\n",
    "            plt.close()\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "    metrics_df.to_csv(os.path.join(OUTPUT_DIR, \"model_performance.csv\"), index=False)\n",
    "    return results, X_test, y_test\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Visualization utilities\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def plot_model_comparison(metrics_df: pd.DataFrame) -> None:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    metrics_df.set_index(\"model\")[[\"R2\", \"RMSE\", \"MAE\"]].plot(kind=\"bar\")\n",
    "    plt.ylabel(\"Metric value\")\n",
    "    plt.title(\"Model performance comparison\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, \"model_comparison.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main pipeline\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def main() -> None:\n",
    "    initialize_gee()\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    boundary = load_boundary(BOUNDARY_PATH)\n",
    "    feature_image = build_feature_stack(boundary)\n",
    "\n",
    "    df = sample_points(feature_image, boundary, SOIL_DATA_PATH)\n",
    "    df.to_csv(os.path.join(OUTPUT_DIR, \"training_samples.csv\"), index=False)\n",
    "\n",
    "    results, X_test, y_test = train_models(df)\n",
    "\n",
    "    metrics_df = pd.read_csv(os.path.join(OUTPUT_DIR, \"model_performance.csv\"))\n",
    "    plot_model_comparison(metrics_df)\n",
    "\n",
    "    best_name = metrics_df.sort_values(\"R2\", ascending=False).iloc[0][\"model\"]\n",
    "    best_model = results[best_name][\"model\"]\n",
    "\n",
    "    print(f\"Best model: {best_name}\")\n",
    "\n",
    "    # Predict across image and export\n",
    "    feature_bands = feature_image.bandNames()\n",
    "    predictors = feature_image.select(feature_bands)\n",
    "    model_img = geemap.sk_export_model(best_model, predictors)\n",
    "\n",
    "    geemap.ee_export_image_to_drive(\n",
    "        model_img,\n",
    "        description=\"salinity_prediction\",\n",
    "        folder=\"gee_outputs\",\n",
    "        region=boundary.geometry(),\n",
    "        scale=30,\n",
    "        fileFormat=\"GeoTIFF\",\n",
    "    )\n",
    "    print(\"Export task started.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  # pragma: no cover - script entry\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d2f8f-4bda-4f5c-a50e-def720e327ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
