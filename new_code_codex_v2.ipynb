{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dca51e-8b25-4f33-853f-9a8c10e808b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ce4f94a6-2a4f-4ceb-b2fb-3d3e38a2dd20\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"import ee\\n\",\n",
    "    \"\\n\",\n",
    "    \"import geemap\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split, GridSearchCV, KFold\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.metrics import r2_score, mean_squared_error\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestRegressor\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.svm import SVR\\n\",\n",
    "    \"\\n\",\n",
    "    \"from sklearn.linear_model import LinearRegression\\n\",\n",
    "    \"\\n\",\n",
    "    \"import xgboost as xgb\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    import shap\\n\",\n",
    "    \"    SHAP_AVAILABLE = True\\n\",\n",
    "    \"except ImportError:\\n\",\n",
    "    \"    SHAP_AVAILABLE = False\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ----------------------------------------------------------------------\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configuration\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ----------------------------------------------------------------------\\n\",\n",
    "    \"\\n\",\n",
    "    \"START_DATE = '2022-07-01'\\n\",\n",
    "    \"\\n\",\n",
    "    \"END_DATE = '2022-10-01'\\n\",\n",
    "    \"BOUNDARY_PATH = '/path/to/bdy.shp'\\n\",\n",
    "    \"SOIL_DATA_PATH = '/path/to/soil_samples.csv'\\n\",\n",
    "    \"\\n\",\n",
    "    \"BOUNDARY_PATH = '/Users/hanxu/geemap/bdy.shp'\\n\",\n",
    "    \"\\n\",\n",
    "    \"SOIL_DATA_PATH = '/Users/hanxu/geemap/material/soil/soil_2022_08.csv'\\n\",\n",
    "    \"\\n\",\n",
    "    \"OUTPUT_DIR = 'outputs'\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"LANDSAT_COLLECTION = 'LANDSAT/LC08/C02/T1_L2'\\n\",\n",
    "    \"\\n\",\n",
    "    \"SENTINEL1_COLLECTION = 'COPERNICUS/S1_GRD'\\n\",\n",
    "    \"\\n\",\n",
    "    \"MODIS_ET_COLLECTION = 'MODIS/061/MOD16A2'\\n\",\n",
    "    \"\\n\",\n",
    "    \"CHIRPS_COLLECTION = 'UCSB-CHG/CHIRPS/DAILY'\\n\",\n",
    "    \"\\n\",\n",
    "    \"SRTM = 'USGS/SRTMGL1_003'\\n\",\n",
    "    \"\\n\",\n",
    "    \"WORLDCOVER = 'ESA/WorldCover/v200'\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"CLOUD_THRESHOLD = 70\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ----------------------------------------------------------------------\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Helper functions\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ----------------------------------------------------------------------\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def initialize_gee():\\n\",\n",
    "    \"\\n\",\n",
    "    \"    \\\"\\\"\\\"Authenticate and initialize Google Earth Engine.\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"\\n\",\n",
    "    \"        ee.Initialize()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    except Exception:\\n\",\n",
    "    \"\\n\",\n",
    "    \"        ee.Authenticate()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        ee.Initialize()\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def load_boundary(path):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return geemap.shp_to_ee(path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def mask_clouds_l8(image):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    qa = image.select('QA_PIXEL')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    cloud = qa.bitwiseAnd(1 << 3).eq(0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    shadow = qa.bitwiseAnd(1 << 4).eq(0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    snow = qa.bitwiseAnd(1 << 5).eq(0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    mask = cloud.And(shadow).And(snow)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return image.updateMask(mask)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def apply_scale(image):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    optical = image.select('SR_B.*').multiply(0.0000275).add(-0.2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    thermal = image.select('ST_B.*').multiply(0.00341802).add(149.0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return image.addBands(optical, None, True).addBands(thermal, None, True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def process_landsat(boundary):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    collection = (\\n\",\n",
    "    \"\\n\",\n",
    "    \"        ee.ImageCollection(LANDSAT_COLLECTION)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filterDate(START_DATE, END_DATE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filterBounds(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .map(apply_scale)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .map(mask_clouds_l8)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    composite = collection.median().clip(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    ndvi = composite.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    si = composite.select('SR_B2').multiply(composite.select('SR_B4')).sqrt().rename('SI1')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return composite.addBands([ndvi, si])\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def process_sentinel1(boundary):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def mask_edge(image):\\n\",\n",
    "    \"\\n\",\n",
    "    \"        edge = image.lt(-30.0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        mask = image.mask().And(edge.Not())\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return image.updateMask(mask)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    collection = (\\n\",\n",
    "    \"\\n\",\n",
    "    \"        ee.ImageCollection(SENTINEL1_COLLECTION)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filterDate(START_DATE, END_DATE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filterBounds(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filter(ee.Filter.eq('instrumentMode', 'IW'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .map(mask_edge)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    vv = collection.select('VV').median()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    vh = collection.select('VH').median()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    ratio = vv.subtract(vh).rename('VV_VH_diff')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return ee.Image.cat([vv, vh, ratio]).clip(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def process_environment(boundary):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    et = (\\n\",\n",
    "    \"\\n\",\n",
    "    \"        ee.ImageCollection(MODIS_ET_COLLECTION)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filterDate(START_DATE, END_DATE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filterBounds(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .select('ET')\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .mean()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .rename('ET')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    precip = (\\n\",\n",
    "    \"\\n\",\n",
    "    \"        ee.ImageCollection(CHIRPS_COLLECTION)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filterDate(START_DATE, END_DATE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .filterBounds(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .select('precipitation')\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .sum()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        .rename('Precip')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    dem = ee.Image(SRTM)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    slope = ee.Terrain.slope(dem).rename('slope')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return ee.Image.cat([et, precip, dem.rename('elevation'), slope]).clip(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def build_feature_stack(boundary):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    l8 = process_landsat(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    s1 = process_sentinel1(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    env = process_environment(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    worldcover = ee.ImageCollection(WORLDCOVER).first().select('Map')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return ee.Image.cat([l8, s1, env, worldcover.rename('landcover')])\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def sample_points(image, boundary, sample_path):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    samples = geemap.shp_to_ee(sample_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    sample = image.sampleRegions(\\n\",\n",
    "    \"\\n\",\n",
    "    \"        collection=samples,\\n\",\n",
    "    \"\\n\",\n",
    "    \"        properties=['salinity'],\\n\",\n",
    "    \"\\n\",\n",
    "    \"        scale=30,\\n\",\n",
    "    \"\\n\",\n",
    "    \"        geometries=True\\n\",\n",
    "    \"\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df = geemap.ee_to_pandas(sample)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return df.dropna()\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def train_models(df):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    X = df.drop(columns=['salinity', 'longitude', 'latitude'], errors='ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"    y = df['salinity']\\n\",\n",
    "    \"\\n\",\n",
    "    \"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    models = {\\n\",\n",
    "    \"\\n\",\n",
    "    \"        'RandomForest': RandomForestRegressor(random_state=42),\\n\",\n",
    "    \"\\n\",\n",
    "    \"        'SVR': SVR(),\\n\",\n",
    "    \"\\n\",\n",
    "    \"        'Linear': LinearRegression(),\\n\",\n",
    "    \"\\n\",\n",
    "    \"        'XGB': xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    params = {\\n\",\n",
    "    \"\\n\",\n",
    "    \"        'RandomForest': {'n_estimators': [100, 200], 'max_depth': [5, 10]},\\n\",\n",
    "    \"\\n\",\n",
    "    \"        'SVR': {'C': [1, 10], 'gamma': ['scale', 'auto']},\\n\",\n",
    "    \"\\n\",\n",
    "    \"        'Linear': {},\\n\",\n",
    "    \"\\n\",\n",
    "    \"        'XGB': {'n_estimators': [100, 200], 'max_depth': [3, 6]}\\n\",\n",
    "    \"\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    metrics_list = []\\n\",\n",
    "    \"    results = {}\\n\",\n",
    "    \"    feature_names = X_train.columns\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for name, model in models.items():\\n\",\n",
    "    \"        grid = GridSearchCV(model, params[name], cv=KFold(n_splits=5, shuffle=True, random_state=42))\\n\",\n",
    "    \"        grid.fit(X_train, y_train)\\n\",\n",
    "    \"        pred = grid.predict(X_test)\\n\",\n",
    "    \"        r2 = r2_score(y_test, pred)\\n\",\n",
    "    \"        rmse = mean_squared_error(y_test, pred, squared=False)\\n\",\n",
    "    \"        results[name] = {'model': grid.best_estimator_, 'r2': r2, 'rmse': rmse}\\n\",\n",
    "    \"        metrics_list.append({'model': name, 'R2': r2, 'RMSE': rmse})\\n\",\n",
    "    \"        print(f'{name}: R2={r2:.3f}, RMSE={rmse:.3f}')\\n\",\n",
    "    \"    return results\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if hasattr(grid.best_estimator_, 'feature_importances_'):\\n\",\n",
    "    \"            importances = grid.best_estimator_.feature_importances_\\n\",\n",
    "    \"            imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\\n\",\n",
    "    \"            imp_df = imp_df.sort_values('importance', ascending=False)\\n\",\n",
    "    \"            print(imp_df.head())\\n\",\n",
    "    \"            imp_df.to_csv(os.path.join(OUTPUT_DIR, f'{name}_feature_importance.csv'), index=False)\\n\",\n",
    "    \"        if SHAP_AVAILABLE:\\n\",\n",
    "    \"            explainer = shap.Explainer(grid.best_estimator_, X_train)\\n\",\n",
    "    \"            shap_values = explainer(X_test)\\n\",\n",
    "    \"            shap_df = pd.DataFrame(shap_values.values, columns=feature_names)\\n\",\n",
    "    \"            shap_df.to_csv(os.path.join(OUTPUT_DIR, f'{name}_shap_values.csv'), index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    metrics_df = pd.DataFrame(metrics_list)\\n\",\n",
    "    \"    metrics_df.to_csv(os.path.join(OUTPUT_DIR, 'model_performance.csv'), index=False)\\n\",\n",
    "    \"    return results, X_test, y_test\\n\",\n",
    "    \"def main():\\n\",\n",
    "    \"\\n\",\n",
    "    \"    initialize_gee()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    os.makedirs(OUTPUT_DIR, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    boundary = load_boundary(BOUNDARY_PATH)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feature_image = build_feature_stack(boundary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df = sample_points(feature_image, boundary, SOIL_DATA_PATH)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df.to_csv(os.path.join(OUTPUT_DIR, 'training_samples.csv'), index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    results = train_models(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    results, X_test, y_test = train_models(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    best_name = max(results, key=lambda k: results[k]['r2'])\\n\",\n",
    "    \"    best_model = results[best_name]['model']\\n\",\n",
    "    \"\\n\",\n",
    "    \"    best_model = results[best_name]['model']\\n\",\n",
    "    \"    pred = best_model.predict(X_test)\\n\",\n",
    "    \"    pd.DataFrame({'y_true': y_test, 'y_pred': pred}).to_csv(\\n\",\n",
    "    \"        os.path.join(OUTPUT_DIR, f'{best_name}_predictions.csv'), index=False\\n\",\n",
    "    \")\\n\",\n",
    "    \"    if SHAP_AVAILABLE:\\n\",\n",
    "    \"        explainer = shap.Explainer(best_model, X_test)\\n\",\n",
    "    \"        shap_values = explainer(X_test)\\n\",\n",
    "    \"        pd.DataFrame(shap_values.values, columns=X_test.columns).to_csv(\\n\",\n",
    "    \"            os.path.join(OUTPUT_DIR, f'{best_name}_shap.csv'), index=False\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    print(f'Best model: {best_name}')\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Predict across image\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feature_bands = feature_image.bandNames()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    predictors = feature_image.select(feature_bands)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    model = geemap.sk_export_model(best_model, predictors)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Export predictions (placeholder, requires geemap>=0.30)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    task = geemap.ee_export_image_to_drive(\\n\",\n",
    "    \"\\n\",\n",
    "    \"        model,\\n\",\n",
    "    \"\\n\",\n",
    "    \"        description='salinity_prediction',\\n\",\n",
    "    \"\\n\",\n",
    "    \"        folder='gee_outputs',\\n\",\n",
    "    \"\\n\",\n",
    "    \"        region=boundary,\\n\",\n",
    "    \"\\n\",\n",
    "    \"        scale=30\\n\",\n",
    "    \"\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print('Export task started.')\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"if __name__ == '__main__':\\n\",\n",
    "    \"    main()\"\n",
    "    \"\\n\",\n",
    "    \"    main()\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.13\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
